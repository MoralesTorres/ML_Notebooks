{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWj9JwZv3IcZZXqGDChl5P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoralesTorres/ML_Notebooks/blob/master/API_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J7ubuyL8ljUj"
      },
      "outputs": [],
      "source": [
        "!pip -q install fastapi uvicorn sqlalchemy pydantic python-multipart pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n"
      ],
      "metadata": {
        "id": "H3_xbfYCuTFd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading, uvicorn\n",
        "\n",
        "def run():\n",
        "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "threading.Thread(target=run, daemon=True).start()\n",
        "print(\"✅ Uvicorn running on port 8000\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowSJbMvuVNq",
        "outputId": "07762b11-43dc-4a4e-fb67-196b12048087"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Uvicorn running on port 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wNcVXGPuh_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing the port\n"
      ],
      "metadata": {
        "id": "lkBeIhTguigH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, re, time\n",
        "\n",
        "p = subprocess.Popen(\n",
        "    [\"./cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8000\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "public_url = None\n",
        "for _ in range(60):\n",
        "    line = p.stdout.readline()\n",
        "    if line:\n",
        "        m = re.search(r\"(https://[-\\w]+\\.trycloudflare\\.com)\", line)\n",
        "        if m:\n",
        "            public_url = m.group(1)\n",
        "            break\n",
        "    time.sleep(0.2)\n",
        "\n",
        "print(\"✅ Public URL:\", public_url)\n",
        "print(\"Swagger:\", public_url + \"/docs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA9ounY4ulEB",
        "outputId": "e776432e-b9a8-4910-8aaa-531a7965172d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Public URL: https://constitute-troy-dispatched-person.trycloudflare.com\n",
            "Swagger: https://constitute-troy-dispatched-person.trycloudflare.com/docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import csv\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from typing import List\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File, Depends, HTTPException\n",
        "from pydantic import BaseModel, Field\n",
        "from sqlalchemy import create_engine, Column, Integer, String, DateTime, ForeignKey\n",
        "from sqlalchemy.orm import sessionmaker, DeclarativeBase, Session\n",
        "from sqlalchemy.exc import IntegrityError\n",
        "\n",
        "# -----------------------------\n",
        "# DB (SQLite local in Colab VM)\n",
        "# -----------------------------\n",
        "DATABASE_URL = \"sqlite:///./challenge.db\"\n",
        "engine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False})\n",
        "SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n",
        "\n",
        "class Base(DeclarativeBase):\n",
        "    pass\n",
        "\n",
        "def get_db():\n",
        "    db = SessionLocal()\n",
        "    try:\n",
        "        yield db\n",
        "    finally:\n",
        "        db.close()\n",
        "\n",
        "# -----------------------------\n",
        "# Models\n",
        "# -----------------------------\n",
        "class Department(Base):\n",
        "    __tablename__ = \"departments\"\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    department = Column(String, nullable=False)\n",
        "\n",
        "class Job(Base):\n",
        "    __tablename__ = \"jobs\"\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    job = Column(String, nullable=False)\n",
        "\n",
        "class Employee(Base):\n",
        "    __tablename__ = \"hired_employees\"\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    name = Column(String, nullable=False)\n",
        "    datetime = Column(DateTime, nullable=False)\n",
        "    department_id = Column(Integer, ForeignKey(\"departments.id\"), nullable=False)\n",
        "    job_id = Column(Integer, ForeignKey(\"jobs.id\"), nullable=False)\n",
        "\n",
        "Base.metadata.create_all(bind=engine)\n",
        "\n",
        "# -----------------------------\n",
        "# Schemas (Batch 1..1000)\n",
        "# -----------------------------\n",
        "MAX_BATCH = 1000\n",
        "\n",
        "class DepartmentCreate(BaseModel):\n",
        "    id: int = Field(..., ge=1)\n",
        "    department: str\n",
        "\n",
        "class JobCreate(BaseModel):\n",
        "    id: int = Field(..., ge=1)\n",
        "    job: str\n",
        "\n",
        "class EmployeeCreate(BaseModel):\n",
        "    id: int = Field(..., ge=1)\n",
        "    name: str\n",
        "    datetime: datetime\n",
        "    department_id: int = Field(..., ge=1)\n",
        "    job_id: int = Field(..., ge=1)\n",
        "\n",
        "def validate_batch(n: int):\n",
        "    if n < 1 or n > MAX_BATCH:\n",
        "        raise HTTPException(status_code=400, detail=f\"Batch must be 1..{MAX_BATCH}. Got {n}\")\n",
        "\n",
        "# -----------------------------\n",
        "# CSV parsing (NO HEADERS)\n",
        "# -----------------------------\n",
        "def parse_departments_csv(path: str):\n",
        "    items = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.reader(f, delimiter=\",\")\n",
        "        for row in reader:\n",
        "            if len(row) < 2:\n",
        "                continue\n",
        "            items.append({\"id\": int(row[0]), \"department\": row[1].strip()})\n",
        "    return items\n",
        "\n",
        "def parse_jobs_csv(path: str):\n",
        "    items = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.reader(f, delimiter=\",\")\n",
        "        for row in reader:\n",
        "            if len(row) < 2:\n",
        "                continue\n",
        "            items.append({\"id\": int(row[0]), \"job\": row[1].strip()})\n",
        "    return items\n",
        "\n",
        "def parse_hired_employees_csv(path: str):\n",
        "    items = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.reader(f, delimiter=\",\")\n",
        "        for row in reader:\n",
        "            if len(row) < 5:\n",
        "                continue\n",
        "            raw_dt = row[2].strip().replace(\"Z\", \"\")\n",
        "            try:\n",
        "                dt = datetime.fromisoformat(raw_dt)\n",
        "            except ValueError:\n",
        "                raise HTTPException(status_code=400, detail=f\"Invalid datetime: {row[2]}\")\n",
        "            items.append({\n",
        "                \"id\": int(row[0]),\n",
        "                \"name\": row[1].strip(),\n",
        "                \"datetime\": dt,\n",
        "                \"department_id\": int(row[3]),\n",
        "                \"job_id\": int(row[4]),\n",
        "            })\n",
        "    return items\n",
        "\n",
        "# -----------------------------\n",
        "# FastAPI\n",
        "# -----------------------------\n",
        "UPLOAD_DIR = \"./uploaded_files\"\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "app = FastAPI(title=\"API Challenge - DB Migration (Colab)\")\n",
        "\n",
        "def save_upload(file: UploadFile) -> str:\n",
        "    path = os.path.join(UPLOAD_DIR, file.filename)\n",
        "    with open(path, \"wb\") as buffer:\n",
        "        shutil.copyfileobj(file.file, buffer)\n",
        "    return path\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "# ---- Upload endpoints (CSV -> DB)\n",
        "@app.post(\"/upload/departments\")\n",
        "def upload_departments(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
        "    path = save_upload(file)\n",
        "    items = parse_departments_csv(path)\n",
        "    validate_batch(len(items))\n",
        "    try:\n",
        "        db.add_all([Department(**x) for x in items])\n",
        "        db.commit()\n",
        "        return {\"table\": \"departments\", \"inserted\": len(items)}\n",
        "    except IntegrityError as e:\n",
        "        db.rollback()\n",
        "        raise HTTPException(status_code=409, detail=str(e.orig))\n",
        "\n",
        "@app.post(\"/upload/jobs\")\n",
        "def upload_jobs(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
        "    path = save_upload(file)\n",
        "    items = parse_jobs_csv(path)\n",
        "    validate_batch(len(items))\n",
        "    try:\n",
        "        db.add_all([Job(**x) for x in items])\n",
        "        db.commit()\n",
        "        return {\"table\": \"jobs\", \"inserted\": len(items)}\n",
        "    except IntegrityError as e:\n",
        "        db.rollback()\n",
        "        raise HTTPException(status_code=409, detail=str(e.orig))\n",
        "\n",
        "@app.post(\"/upload/hired_employees\")\n",
        "def upload_hired_employees(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
        "    path = save_upload(file)\n",
        "    items = parse_hired_employees_csv(path)\n",
        "    validate_batch(len(items))\n",
        "    try:\n",
        "        db.add_all([Employee(**x) for x in items])\n",
        "        db.commit()\n",
        "        return {\"table\": \"hired_employees\", \"inserted\": len(items)}\n",
        "    except IntegrityError as e:\n",
        "        db.rollback()\n",
        "        raise HTTPException(status_code=409, detail=str(e.orig))\n",
        "\n",
        "# ---- Batch JSON endpoints (1..1000)\n",
        "@app.post(\"/batch/departments\")\n",
        "def batch_departments(payload: List[DepartmentCreate], db: Session = Depends(get_db)):\n",
        "    validate_batch(len(payload))\n",
        "    try:\n",
        "        db.add_all([Department(**x.model_dump()) for x in payload])\n",
        "        db.commit()\n",
        "        return {\"table\": \"departments\", \"inserted\": len(payload)}\n",
        "    except IntegrityError as e:\n",
        "        db.rollback()\n",
        "        raise HTTPException(status_code=409, detail=str(e.orig))\n",
        "\n",
        "@app.post(\"/batch/jobs\")\n",
        "def batch_jobs(payload: List[JobCreate], db: Session = Depends(get_db)):\n",
        "    validate_batch(len(payload))\n",
        "    try:\n",
        "        db.add_all([Job(**x.model_dump()) for x in payload])\n",
        "        db.commit()\n",
        "        return {\"table\": \"jobs\", \"inserted\": len(payload)}\n",
        "    except IntegrityError as e:\n",
        "        db.rollback()\n",
        "        raise HTTPException(status_code=409, detail=str(e.orig))\n",
        "\n",
        "@app.post(\"/batch/hired_employees\")\n",
        "def batch_hired_employees(payload: List[EmployeeCreate], db: Session = Depends(get_db)):\n",
        "    validate_batch(len(payload))\n",
        "    try:\n",
        "        db.add_all([Employee(**x.model_dump()) for x in payload])\n",
        "        db.commit()\n",
        "        return {\"table\": \"hired_employees\", \"inserted\": len(payload)}\n",
        "    except IntegrityError as e:\n",
        "        db.rollback()\n",
        "        raise HTTPException(status_code=409, detail=str(e.orig))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onqG849itxVU",
        "outputId": "b9578f71-7641-4b6a-d578-79bb145e2c31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5iynyUWLvRux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cloud connection further"
      ],
      "metadata": {
        "id": "kHA-6GYBvlef"
      }
    }
  ]
}