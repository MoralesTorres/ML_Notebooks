{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia 1 de TextgGenerationLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXbeWbe6+qPqoOq4y4dL5C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoralesTorres/ML_Notebooks/blob/master/Copia_1_de_TextgGenerationLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfdDuCiMgT8q"
      },
      "source": [
        "1. IMPORTING DEPENDENCIES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTZDVs0Tjcyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17f1d9e-7346-4409-8bdd-a4dd0e571475"
      },
      "source": [
        "!pip install -q gradio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 6.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 25.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 962kB 25.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 53.2MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for Flask-BasicAuth (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1jwzAFAqxjT"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "import string \n",
        "import requests \n",
        "import math\n",
        "import re\n",
        "import time\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U7deAQhrRG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4369a6-1526-447f-c48f-631cfd4497a7"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW8cmpCErqmt"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/basic.txt\",\n",
        "          mode='r',\n",
        "          encoding='utf-8') as f:\n",
        "    advanced = f.read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "XyggXHhLr8yY",
        "outputId": "ba3de373-a4cf-42bc-910c-b7b4f376430c"
      },
      "source": [
        "data = advanced.split('\\n')\n",
        "data[0]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'On weekdays except Friday (this is, from Monday to Thursday) I get up early – at half past seven. I have a white coffee and biscuits for breakfast and I go to work. I work from eight to five. I always have lunch at the office. I usually have a sandwich and a juice or a piece of fruit for lunch.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv7JcfSMtBZx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LgPUTQagtMp7",
        "outputId": "91987025-75c1-43a1-ecd0-41969dc82654"
      },
      "source": [
        "data[3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"On Friday I work from nine to one. Then I have lunch and at four I go to my course. I'm taking a course on the Internet. It's interesting. I finish at six. Then I go out for a drink with my friends.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65T-y30XtPx7",
        "outputId": "d8c2de25-cbd7-445e-a734-dc2a7711f6a1"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYwQAkleteV0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "359f02ae-0424-4a16-b8fe-a4ce3ff110a3"
      },
      "source": [
        "data = \" \".join(data)\n",
        "data[:1000]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"On weekdays except Friday (this is, from Monday to Thursday) I get up early – at half past seven. I have a white coffee and biscuits for breakfast and I go to work. I work from eight to five. I always have lunch at the office. I usually have a sandwich and a juice or a piece of fruit for lunch.  In the afternoon, I go to my English class. That's from five to six. After that, I go shopping for food and things for the house. Then I often listen to my audio CD. And I listen and repeat! Sometimes I do my homework. At about half past eight I cook dinner for my family and me. We usually have dinner at nine thirty. Then we watch TV or read. I often go to bed at about half past eleven. On Friday I work from nine to one. Then I have lunch and at four I go to my course. I'm taking a course on the Internet. It's interesting. I finish at six. Then I go out for a drink with my friends. At the weekend my day is different. On Saturday, in the morning, oh well, on Saturday morning my family and I do s\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SwqFn-uuBUT"
      },
      "source": [
        "def clean_text(doc):\n",
        "  tokens = doc.split()\n",
        "  table = str.maketrans('' , '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88LVOAmIvXS-",
        "outputId": "f12da708-e267-4261-9813-0779625d8349"
      },
      "source": [
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['on', 'weekdays', 'except', 'friday', 'this', 'is', 'from', 'monday', 'to', 'thursday', 'i', 'get', 'up', 'early', 'at', 'half', 'past', 'seven', 'i', 'have', 'a', 'white', 'coffee', 'and', 'biscuits', 'for', 'breakfast', 'and', 'i', 'go', 'to', 'work', 'i', 'work', 'from', 'eight', 'to', 'five', 'i', 'always', 'have', 'lunch', 'at', 'the', 'office', 'i', 'usually', 'have', 'a', 'sandwich']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpSCE5rwet5",
        "outputId": "520cb898-dc61-42a4-dc2b-db7a1726a4ab"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "292"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq742MlfwjXO",
        "outputId": "42aa506a-d436-446a-b7ca-ddc71ecb682e"
      },
      "source": [
        "len(set(tokens))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRCf_l9ehLTp",
        "outputId": "76c48d44-19b2-4352-ae86-2de785ca3738"
      },
      "source": [
        "\n",
        "from random import randint\n",
        "\n",
        "def generate_sequence(length, n_unique):\n",
        "  return [randint(0, n_unique-1) for _ in range(length)]\n",
        "\n",
        "sequence = generate_sequence(10, 50)\n",
        "print(sequence)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 43, 25, 4, 43, 43, 37, 2, 20, 41]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGklBHb8hiY3"
      },
      "source": [
        "def one_hot_encode(sequence, n_unique):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-3hyvNGhrjw"
      },
      "source": [
        "\n",
        "\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voG9_frMh0bv",
        "outputId": "e45e61f1-b6a3-428b-eb61-b4dafec56d35"
      },
      "source": [
        "\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "\n",
        "# generate a sequence of random integers\n",
        "def generate_sequence(length, n_unique):\n",
        "\treturn [randint(0, n_unique-1) for _ in range(length)]\n",
        "\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)\n",
        "\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "# generate random sequence\n",
        "sequence = generate_sequence(5, 50)\n",
        "print(sequence)\n",
        "# one hot encode\n",
        "encoded = one_hot_encode(sequence, 50)\n",
        "print(encoded)\n",
        "# decode\n",
        "decoded = one_hot_decode(encoded)\n",
        "print(decoded)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[42, 23, 13, 35, 9]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[42, 23, 13, 35, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoAJIGM_iDVo"
      },
      "source": [
        "# prepare data for the LSTM\n",
        "def get_pair(n_in, n_out, n_unique):\n",
        "\t# generate random sequence\n",
        "\tsequence_in = generate_sequence(n_in, n_unique)\n",
        "\tsequence_out = sequence_in[:n_out] + [0 for _ in range(n_in-n_out)]\n",
        "\t# one hot encode\n",
        "\tX = one_hot_encode(sequence_in, n_unique)\n",
        "\ty = one_hot_encode(sequence_out, n_unique)\n",
        "\t# reshape as 3D\n",
        "\tX = X.reshape((1, X.shape[0], X.shape[1]))\n",
        "\ty = y.reshape((1, y.shape[0], y.shape[1]))\n",
        "\treturn X,y"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGSg_mCeiElP",
        "outputId": "53e5f898-7481-4707-e22f-b0df067cb179"
      },
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        " \n",
        "# generate a sequence of random integers\n",
        "def generate_sequence(length, n_unique):\n",
        "\treturn [randint(0, n_unique-1) for _ in range(length)]\n",
        " \n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)\n",
        " \n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        " \n",
        "# prepare data for the LSTM\n",
        "def get_pair(n_in, n_out, n_unique):\n",
        "\t# generate random sequence\n",
        "\tsequence_in = generate_sequence(n_in, n_unique)\n",
        "\tsequence_out = sequence_in[:n_out] + [0 for _ in range(n_in-n_out)]\n",
        "\t# one hot encode\n",
        "\tX = one_hot_encode(sequence_in, n_unique)\n",
        "\ty = one_hot_encode(sequence_out, n_unique)\n",
        "\t# reshape as 3D\n",
        "\tX = X.reshape((1, X.shape[0], X.shape[1]))\n",
        "\ty = y.reshape((1, y.shape[0], y.shape[1]))\n",
        "\treturn X,y\n",
        " \n",
        "# generate random sequence\n",
        "X, y = get_pair(5, 2, 50)\n",
        "print(X.shape, y.shape)\n",
        "print('X=%s, y=%s' % (one_hot_decode(X[0]), one_hot_decode(y[0])))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5, 50) (1, 5, 50)\n",
            "X=[33, 12, 42, 47, 40], y=[33, 12, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOq0bng1iEoX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBltTNR4iErS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKMMC7-8iEvS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtUc7dZPxAMI",
        "outputId": "2077c321-9ecf-42c1-a3b4-7024081eb26d"
      },
      "source": [
        "length = 10 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 5000:\n",
        "    break\n",
        "\n",
        "print(len(lines))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6gfOaLjqZuaU",
        "outputId": "cf1f7c55-387b-48e4-fb5f-1c3bfed5286f"
      },
      "source": [
        "lines[2]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'except friday this is from monday to thursday i get up'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnNM9qroyyJ5"
      },
      "source": [
        "## Construction of our LSTM model / Training X and Y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "McTn9gREyY-P",
        "outputId": "a4488cec-d32d-4495-ba59-c120d778d985"
      },
      "source": [
        "tokens[30]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeP4la-izKNT"
      },
      "source": [
        "import numpy as np \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzYUYwT6zwzQ"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybuHI89A0PpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b1a727-30aa-466a-a33a-5d9e179363b5"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  9, 123, 121,  49, 120,  47,  16, 119,   3, 117])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UxRoMta1RcS",
        "outputId": "f717b62e-be6d-45ff-8561-832b1ef49acc"
      },
      "source": [
        "X[1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([123, 121,  49, 120,  47,  16, 119,   3, 117,   1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXp1nRvz12Ff"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rUoqRQi1ZZS",
        "outputId": "e8929ad8-36b2-40e0-b2eb-7b419c881f33"
      },
      "source": [
        "y[1]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7P79ceW1m2I",
        "outputId": "33e30aa2-1ae8-4cd1-a524-2ad4ebc697dc"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size )\n",
        "X.shape[1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUJAkcAz20hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687a78d3-e0f6-4e4b-ee68-4bc11742d468"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohv0WKTNH89H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W17FVAMlH9Am"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK7o6QKa3B3T"
      },
      "source": [
        "## LSTM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMtzdJGvJTtN",
        "outputId": "566534f7-c006-486b-83e3-66eabf606dd8"
      },
      "source": [
        "pip install attention"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting attention\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/3f/d8b19195a2f5827dcbf0ee6d7e6fe4352f42dcc60693bdb1e431440c8b59/attention-4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from attention) (1.19.5)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.7/dist-packages (from attention) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.12.4)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (54.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1->attention) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1->attention) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1->attention) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1->attention) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1->attention) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1->attention) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1->attention) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1->attention) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1->attention) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1->attention) (2.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1->attention) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1->attention) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1->attention) (3.4.1)\n",
            "Installing collected packages: attention\n",
            "Successfully installed attention-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "492I7HBvYlne",
        "outputId": "1fa114d7-9c2d-4f79-e845-4f2c4e47b4a8"
      },
      "source": [
        "pip install keras-self-attention"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/34/e21dc6adcdab2be03781bde78c6c5d2b2136d35a1dd3e692d7e160ba062a/keras-self-attention-0.49.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.49.0-cp37-none-any.whl size=19468 sha256=5e22d76296c1ff125b4af979e52e6e4b438e9c0a1ef51d6ad76b8521a8010761\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/9d/c5/26693a5092d9313daeae94db04818fc0a2b7a48ea381989f34\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.49.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbzx1RRWjKsc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rytz4nfBZDQc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfhKcEdxZDSz",
        "outputId": "2390ab72-642c-44f3-8cac-783bcce19e84"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 50)            6200      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 10, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 124)               12524     \n",
            "=================================================================\n",
            "Total params: 169,624\n",
            "Trainable params: 169,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8peP4AohkTvw"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nPeCet6kTzQ",
        "outputId": "60ab0ace-dea3-4a53-86c3-7d5f5f244439"
      },
      "source": [
        "model.fit(X, y, batch_size = 50, epochs = 250)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "6/6 [==============================] - 33s 7ms/step - loss: 4.8184 - accuracy: 0.0288\n",
            "Epoch 2/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.8004 - accuracy: 0.0933\n",
            "Epoch 3/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.7413 - accuracy: 0.0801\n",
            "Epoch 4/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.5254 - accuracy: 0.0831\n",
            "Epoch 5/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.4233 - accuracy: 0.0788\n",
            "Epoch 6/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.3626 - accuracy: 0.0878\n",
            "Epoch 7/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2841 - accuracy: 0.0879\n",
            "Epoch 8/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2240 - accuracy: 0.0825\n",
            "Epoch 9/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.3219 - accuracy: 0.0766\n",
            "Epoch 10/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2173 - accuracy: 0.0940\n",
            "Epoch 11/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2403 - accuracy: 0.0771\n",
            "Epoch 12/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2360 - accuracy: 0.0922\n",
            "Epoch 13/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.1440 - accuracy: 0.0885\n",
            "Epoch 14/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.1470 - accuracy: 0.0889\n",
            "Epoch 15/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.0237 - accuracy: 0.0872\n",
            "Epoch 16/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.0494 - accuracy: 0.1040\n",
            "Epoch 17/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.0323 - accuracy: 0.0791\n",
            "Epoch 18/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.9976 - accuracy: 0.0999\n",
            "Epoch 19/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.8544 - accuracy: 0.1114\n",
            "Epoch 20/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.9221 - accuracy: 0.0929\n",
            "Epoch 21/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.8447 - accuracy: 0.0882\n",
            "Epoch 22/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.7737 - accuracy: 0.0981\n",
            "Epoch 23/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.7328 - accuracy: 0.0854\n",
            "Epoch 24/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.6771 - accuracy: 0.0803\n",
            "Epoch 25/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.6282 - accuracy: 0.1032\n",
            "Epoch 26/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.5959 - accuracy: 0.1052\n",
            "Epoch 27/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4933 - accuracy: 0.0896\n",
            "Epoch 28/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.5473 - accuracy: 0.0813\n",
            "Epoch 29/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4414 - accuracy: 0.1336\n",
            "Epoch 30/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4383 - accuracy: 0.1175\n",
            "Epoch 31/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4025 - accuracy: 0.1093\n",
            "Epoch 32/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.3467 - accuracy: 0.1200\n",
            "Epoch 33/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.3261 - accuracy: 0.1163\n",
            "Epoch 34/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.1814 - accuracy: 0.1730\n",
            "Epoch 35/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.2765 - accuracy: 0.1297\n",
            "Epoch 36/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.1119 - accuracy: 0.1611\n",
            "Epoch 37/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.0861 - accuracy: 0.1621\n",
            "Epoch 38/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.0754 - accuracy: 0.1910\n",
            "Epoch 39/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.0331 - accuracy: 0.1607\n",
            "Epoch 40/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.0178 - accuracy: 0.1424\n",
            "Epoch 41/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.9419 - accuracy: 0.1994\n",
            "Epoch 42/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.8526 - accuracy: 0.2046\n",
            "Epoch 43/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.7746 - accuracy: 0.2099\n",
            "Epoch 44/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.7543 - accuracy: 0.1879\n",
            "Epoch 45/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.7244 - accuracy: 0.2283\n",
            "Epoch 46/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.6169 - accuracy: 0.2559\n",
            "Epoch 47/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.5638 - accuracy: 0.2781\n",
            "Epoch 48/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5312 - accuracy: 0.2846\n",
            "Epoch 49/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.4702 - accuracy: 0.3119\n",
            "Epoch 50/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4545 - accuracy: 0.3044\n",
            "Epoch 51/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4221 - accuracy: 0.2535\n",
            "Epoch 52/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3579 - accuracy: 0.3126\n",
            "Epoch 53/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.2753 - accuracy: 0.3446\n",
            "Epoch 54/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.2527 - accuracy: 0.3649\n",
            "Epoch 55/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.2449 - accuracy: 0.3316\n",
            "Epoch 56/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.2141 - accuracy: 0.3372\n",
            "Epoch 57/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.1998 - accuracy: 0.3362\n",
            "Epoch 58/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.1080 - accuracy: 0.3932\n",
            "Epoch 59/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.1693 - accuracy: 0.3541\n",
            "Epoch 60/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0729 - accuracy: 0.3921\n",
            "Epoch 61/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9204 - accuracy: 0.4594\n",
            "Epoch 62/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9268 - accuracy: 0.4447\n",
            "Epoch 63/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8913 - accuracy: 0.4117\n",
            "Epoch 64/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8123 - accuracy: 0.4793\n",
            "Epoch 65/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7670 - accuracy: 0.4980\n",
            "Epoch 66/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7771 - accuracy: 0.5136\n",
            "Epoch 67/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7491 - accuracy: 0.4792\n",
            "Epoch 68/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8408 - accuracy: 0.4349\n",
            "Epoch 69/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8050 - accuracy: 0.4768\n",
            "Epoch 70/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6571 - accuracy: 0.5080\n",
            "Epoch 71/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6714 - accuracy: 0.5117\n",
            "Epoch 72/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6063 - accuracy: 0.5164\n",
            "Epoch 73/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5750 - accuracy: 0.5225\n",
            "Epoch 74/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5162 - accuracy: 0.6068\n",
            "Epoch 75/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4215 - accuracy: 0.6438\n",
            "Epoch 76/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4337 - accuracy: 0.6396\n",
            "Epoch 77/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4618 - accuracy: 0.6137\n",
            "Epoch 78/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3526 - accuracy: 0.6452\n",
            "Epoch 79/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4087 - accuracy: 0.5677\n",
            "Epoch 80/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3681 - accuracy: 0.6461\n",
            "Epoch 81/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3654 - accuracy: 0.5907\n",
            "Epoch 82/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2918 - accuracy: 0.6063\n",
            "Epoch 83/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2268 - accuracy: 0.6919\n",
            "Epoch 84/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2755 - accuracy: 0.6756\n",
            "Epoch 85/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2024 - accuracy: 0.7131\n",
            "Epoch 86/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1604 - accuracy: 0.6970\n",
            "Epoch 87/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1416 - accuracy: 0.7165\n",
            "Epoch 88/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1032 - accuracy: 0.7241\n",
            "Epoch 89/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1319 - accuracy: 0.6905\n",
            "Epoch 90/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1447 - accuracy: 0.6941\n",
            "Epoch 91/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.0096 - accuracy: 0.7546\n",
            "Epoch 92/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0083 - accuracy: 0.7328\n",
            "Epoch 93/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9484 - accuracy: 0.7441\n",
            "Epoch 94/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9556 - accuracy: 0.7453\n",
            "Epoch 95/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9246 - accuracy: 0.7640\n",
            "Epoch 96/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9605 - accuracy: 0.7705\n",
            "Epoch 97/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9072 - accuracy: 0.7669\n",
            "Epoch 98/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.8752 - accuracy: 0.7825\n",
            "Epoch 99/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9257 - accuracy: 0.7681\n",
            "Epoch 100/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.8651 - accuracy: 0.7896\n",
            "Epoch 101/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.8683 - accuracy: 0.7658\n",
            "Epoch 102/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.8373 - accuracy: 0.7931\n",
            "Epoch 103/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.7929 - accuracy: 0.8095\n",
            "Epoch 104/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.8204 - accuracy: 0.7655\n",
            "Epoch 105/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7906 - accuracy: 0.8004\n",
            "Epoch 106/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7646 - accuracy: 0.8317\n",
            "Epoch 107/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7210 - accuracy: 0.8086\n",
            "Epoch 108/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7391 - accuracy: 0.8057\n",
            "Epoch 109/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.8329\n",
            "Epoch 110/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6838 - accuracy: 0.8437\n",
            "Epoch 111/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.7370 - accuracy: 0.8119\n",
            "Epoch 112/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7546 - accuracy: 0.8213\n",
            "Epoch 113/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.7279 - accuracy: 0.7956\n",
            "Epoch 114/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7373 - accuracy: 0.8293\n",
            "Epoch 115/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6890 - accuracy: 0.8168\n",
            "Epoch 116/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 0.8217\n",
            "Epoch 117/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5950 - accuracy: 0.8799\n",
            "Epoch 118/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6452 - accuracy: 0.8451\n",
            "Epoch 119/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6393 - accuracy: 0.8300\n",
            "Epoch 120/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.8697\n",
            "Epoch 121/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.8719\n",
            "Epoch 122/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5531 - accuracy: 0.8510\n",
            "Epoch 123/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5767 - accuracy: 0.8453\n",
            "Epoch 124/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5916 - accuracy: 0.8495\n",
            "Epoch 125/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5696 - accuracy: 0.8457\n",
            "Epoch 126/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.8529\n",
            "Epoch 127/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.8446\n",
            "Epoch 128/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5727 - accuracy: 0.8450\n",
            "Epoch 129/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.9006\n",
            "Epoch 130/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.8776\n",
            "Epoch 131/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.9080\n",
            "Epoch 132/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5731 - accuracy: 0.8888\n",
            "Epoch 133/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5578 - accuracy: 0.8830\n",
            "Epoch 134/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.8798\n",
            "Epoch 135/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5501 - accuracy: 0.8635\n",
            "Epoch 136/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.9049\n",
            "Epoch 137/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.9133\n",
            "Epoch 138/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.9232\n",
            "Epoch 139/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.9219\n",
            "Epoch 140/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.8983\n",
            "Epoch 141/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.8911\n",
            "Epoch 142/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.9144\n",
            "Epoch 143/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.9043\n",
            "Epoch 144/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.9059\n",
            "Epoch 145/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.8917\n",
            "Epoch 146/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8948\n",
            "Epoch 147/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3614 - accuracy: 0.9155\n",
            "Epoch 148/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.9372\n",
            "Epoch 149/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.9197\n",
            "Epoch 150/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3240 - accuracy: 0.9416\n",
            "Epoch 151/250\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3088 - accuracy: 0.9400\n",
            "Epoch 152/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2990 - accuracy: 0.9487\n",
            "Epoch 153/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2908 - accuracy: 0.9482\n",
            "Epoch 154/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2778 - accuracy: 0.9677\n",
            "Epoch 155/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2802 - accuracy: 0.9465\n",
            "Epoch 156/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2700 - accuracy: 0.9394\n",
            "Epoch 157/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2387 - accuracy: 0.9626\n",
            "Epoch 158/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2383 - accuracy: 0.9639\n",
            "Epoch 159/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.9581\n",
            "Epoch 160/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2290 - accuracy: 0.9512\n",
            "Epoch 161/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2660 - accuracy: 0.9587\n",
            "Epoch 162/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2430 - accuracy: 0.9621\n",
            "Epoch 163/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2092 - accuracy: 0.9637\n",
            "Epoch 164/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2155 - accuracy: 0.9633\n",
            "Epoch 165/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2093 - accuracy: 0.9734\n",
            "Epoch 166/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.9722\n",
            "Epoch 167/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2037 - accuracy: 0.9707\n",
            "Epoch 168/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1860 - accuracy: 0.9741\n",
            "Epoch 169/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2031 - accuracy: 0.9525\n",
            "Epoch 170/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1967 - accuracy: 0.9645\n",
            "Epoch 171/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2106 - accuracy: 0.9645\n",
            "Epoch 172/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1603 - accuracy: 0.9797\n",
            "Epoch 173/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1813 - accuracy: 0.9640\n",
            "Epoch 174/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9656\n",
            "Epoch 175/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1774 - accuracy: 0.9598\n",
            "Epoch 176/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9804\n",
            "Epoch 177/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1708 - accuracy: 0.9746\n",
            "Epoch 178/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1531 - accuracy: 0.9775\n",
            "Epoch 179/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.9829\n",
            "Epoch 180/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1561 - accuracy: 0.9815\n",
            "Epoch 181/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9830\n",
            "Epoch 182/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1754 - accuracy: 0.9590\n",
            "Epoch 183/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2189 - accuracy: 0.9496\n",
            "Epoch 184/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3131 - accuracy: 0.9053\n",
            "Epoch 185/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2459 - accuracy: 0.9398\n",
            "Epoch 186/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2526 - accuracy: 0.9444\n",
            "Epoch 187/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2962 - accuracy: 0.9100\n",
            "Epoch 188/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.2956 - accuracy: 0.9134\n",
            "Epoch 189/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.9049\n",
            "Epoch 190/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.8901\n",
            "Epoch 191/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.8838\n",
            "Epoch 192/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.9069\n",
            "Epoch 193/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.9128\n",
            "Epoch 194/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.8958\n",
            "Epoch 195/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.8717\n",
            "Epoch 196/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.8689\n",
            "Epoch 197/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8665\n",
            "Epoch 198/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8984\n",
            "Epoch 199/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.9126\n",
            "Epoch 200/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.9082\n",
            "Epoch 201/250\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2941 - accuracy: 0.9273\n",
            "Epoch 202/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2939 - accuracy: 0.9297\n",
            "Epoch 203/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3000 - accuracy: 0.9378\n",
            "Epoch 204/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3470 - accuracy: 0.9078\n",
            "Epoch 205/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3227 - accuracy: 0.9182\n",
            "Epoch 206/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3144 - accuracy: 0.8812\n",
            "Epoch 207/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3010 - accuracy: 0.9093\n",
            "Epoch 208/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2247 - accuracy: 0.9491\n",
            "Epoch 209/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1779 - accuracy: 0.9787\n",
            "Epoch 210/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9721\n",
            "Epoch 211/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1744 - accuracy: 0.9717\n",
            "Epoch 212/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1432 - accuracy: 0.9818\n",
            "Epoch 213/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9823\n",
            "Epoch 214/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9798\n",
            "Epoch 215/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 0.9897\n",
            "Epoch 216/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1186 - accuracy: 0.9813\n",
            "Epoch 217/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0997 - accuracy: 0.9826\n",
            "Epoch 218/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1435 - accuracy: 0.9741\n",
            "Epoch 219/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9921\n",
            "Epoch 220/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9850\n",
            "Epoch 221/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9952\n",
            "Epoch 222/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9902\n",
            "Epoch 223/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9935\n",
            "Epoch 224/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9902\n",
            "Epoch 225/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9930\n",
            "Epoch 226/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9902\n",
            "Epoch 227/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 0.9902\n",
            "Epoch 228/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9906\n",
            "Epoch 229/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9914\n",
            "Epoch 230/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9892\n",
            "Epoch 231/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9886\n",
            "Epoch 232/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9878\n",
            "Epoch 233/250\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0630 - accuracy: 0.9921\n",
            "Epoch 234/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9930\n",
            "Epoch 235/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0607 - accuracy: 0.9967\n",
            "Epoch 236/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 0.9890\n",
            "Epoch 237/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9883\n",
            "Epoch 238/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0604 - accuracy: 0.9937\n",
            "Epoch 239/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.9974\n",
            "Epoch 240/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0584 - accuracy: 0.9890\n",
            "Epoch 241/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 0.9974\n",
            "Epoch 242/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 0.9937\n",
            "Epoch 243/250\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9921\n",
            "Epoch 244/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9909\n",
            "Epoch 245/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 0.9930\n",
            "Epoch 246/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9968\n",
            "Epoch 247/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9914\n",
            "Epoch 248/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9886\n",
            "Epoch 249/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9952\n",
            "Epoch 250/250\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbee0295b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0RinKKVkT2Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wcDffJ3MlswC",
        "outputId": "83dae6b0-54b9-4f1c-ed30-cc345ed612f0"
      },
      "source": [
        "seed_text=lines[150]\n",
        "seed_text"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'have lunch and at four i go to my course im'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbZ_Cg_1lszx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxQNVl-NKElr"
      },
      "source": [
        "\n",
        "import sys, os, re, csv, codecs, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2JECigBSll3",
        "outputId": "e9a45a38-48bc-4537-c1b9-d51a318604ab"
      },
      "source": [
        "\n",
        "batch_size = 64\n",
        "epochs = 2\n",
        "model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.0489 - accuracy: 0.9921 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0482 - accuracy: 0.9921 - val_loss: 0.0462 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe22087550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "Lcp3-fbzKHJD",
        "outputId": "d06b816c-094b-4bca-f601-7a2a74e84cbf"
      },
      "source": [
        "\n",
        "history = model.history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "# Get number of epochs\\n\",\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\\n\",\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\\n\",\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAd8UlEQVR4nO3df5xddX3n8dfbSYJmSfiRGRfJhAQlrB11DPQ2UR+tCWp0AGskupugQbFitgjdrm2ssLSFRtPAFrVri2B8GCBVAuq27qyGJpYkOyhBc2MgJijZEcH8gHUEQiQU6YTP/nG+E04uk5mTzJ0ZZs77+Xjcx5z7Pd/vud/vncl93/M99+ariMDMzMrnZcPdATMzGx4OADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgB0i6U5JH6533eEk6WFJ7xiE44akM9L2TZL+okjdY3icD0pad6z9NOuL/D2AkU3S07m744HfAAfT/f8cEV8b+l69dEh6GLgkIv6lzscNYHpEdNarrqRpwM+BsRHRXY9+mvVlzHB3wAYmIo7v2e7rxU7SGL+o2EuF/x5fGjwFNEpJmiNpt6RPSXoMuFnSSZK+LalL0pNpuznXZqOkS9L2xZK+J+n6VPfnks49xrqnS+qQ9GtJ/yLpBklfPUK/i/Tx05K+n463TlJjbv9Fkh6R9Likq/p4fmZJekxSQ67sAknb0vZMSZsk7ZP0qKS/lzTuCMe6RdJncvc/mdrslfQHNXXPl7RV0n5JuyRdk9vdkX7uk/S0pDf3PLe59m+RtFnSU+nnW4o+N0f5PJ8s6eY0hiclfSu3b56k+9IYfiapLZUfNt0m6Zqe37OkaWkq7KOSfgGsT+XfSL+Hp9LfyOty7V8h6bPp9/lU+ht7haTvSPqjmvFsk3RBb2O1I3MAjG6nACcDU4HFZL/vm9P904B/Bf6+j/azgAeBRuC/A1+RpGOoexvwQ2AScA1wUR+PWaSPHwA+ArwSGAcsAZDUAtyYjn9qerxmehERPwAOAG+rOe5tafsg8Ik0njcDbwc+3ke/SX1oS/2ZC0wHaq8/HAA+BJwInA9cKum9ad9b088TI+L4iNhUc+yTge8AX0hj+xzwHUmTasbwouemF/09z/9ANqX4unSsz6c+zARWAZ9MY3gr8PCRno9ezAZ+C3hXun8n2fP0SuBHQH7K8nrgt4G3kP0d/xnwPHArsKinkqQ3ApPJnhs7GhHh2yi5kf1DfEfangM8B7y8j/ozgCdz9zeSTSEBXAx05vaNBwI45Wjqkr24dAPjc/u/Cny14Jh66+Of5+5/HPjntP2XwO25ff8uPQfvOMKxPwOsTNsTyF6cpx6h7n8F/il3P4Az0vYtwGfS9krg2ly9M/N1eznu3wKfT9vTUt0xuf0XA99L2xcBP6xpvwm4uL/n5mieZ+BVZC+0J/VS70s9/e3r7y/dv6bn95wb26v76MOJqc4JZAH1r8Abe6n3cuBJsusqkAXFF4f639touPkMYHTriohne+5IGi/pS+mUej/ZlMOJ+WmQGo/1bETEM2nz+KOseyrwRK4MYNeROlywj4/ltp/J9enU/LEj4gDw+JEei+zd/nxJxwHzgR9FxCOpH2emaZHHUj/+muxsoD+H9QF4pGZ8syRtSFMvTwF/WPC4Pcd+pKbsEbJ3vz2O9Nwcpp/neQrZ7+zJXppOAX5WsL+9OfTcSGqQdG2aRtrPC2cSjen28t4eK/1N3wEskvQy4EKyMxY7Sg6A0a32I15/CvwHYFZETOSFKYcjTevUw6PAyZLG58qm9FF/IH18NH/s9JiTjlQ5Ih4gewE9l8OnfyCbSvop2bvMicB/O5Y+kJ0B5d0GtANTIuIE4Kbccfv7SN5esimbvNOAPQX6Vauv53kX2e/sxF7a7QJec4RjHiA7++txSi918mP8ADCPbJrsBLKzhJ4+/Ap4to/HuhX4INnU3DNRM11mxTgAymUC2Wn1vjSffPVgP2B6R10FrpE0TtKbgd8fpD5+E3i3pN9NF2yX0v/f+G3AH5O9AH6jph/7gaclvRa4tGAfvg5cLKklBVBt/yeQvbt+Ns2nfyC3r4ts6uXVRzj2GuBMSR+QNEbSAqAF+HbBvtX2o9fnOSIeJZub/2K6WDxWUk9AfAX4iKS3S3qZpMnp+QG4D1iY6leA9xfow2/IztLGk51l9fThebLptM9JOjWdLbw5na2RXvCfBz6L3/0fMwdAufwt8Aqyd1f3Av88RI/7QbILqY+TzbvfQfYPvzfH3MeI2AFcRvai/ijZPPHufpqtJrswuT4ifpUrX0L24vxr4Mupz0X6cGcaw3qgM/3M+ziwVNKvya5ZfD3X9hlgGfB9ZZ8+elPNsR8H3k327v1xsoui767pd1H9Pc8XAf9Gdhb0S7JrIETED8kuMn8eeAr4P7xwVvIXZO/YnwT+isPPqHqziuwMbA/wQOpH3hLgx8Bm4AngOg5/zVoFvIHsmpIdA38RzIacpDuAn0bEoJ+B2Ogl6UPA4oj43eHuy0jlMwAbdJJ+R9Jr0pRBG9m877f6a2d2JGl67ePAiuHuy0jmALChcArZRxSfJvsM+6URsXVYe2QjlqR3kV0v+X/0P81kffAUkJlZSfkMwMyspEbUfwbX2NgY06ZNG+5umJmNKFu2bPlVRDTVlo+oAJg2bRrVanW4u2FmNqJIqv0GOeApIDOz0nIAmJmVlAPAzKykHABmZiXlADAzK6lCASBppaRfStp+hP2S9AVJnWlptrNz+z4s6f+m24dz5b8t6cepzRf6WGnKzMwGQdEzgFuAtj72n0u2rNt0sqUHb4RDS9hdTbZc4EzgakknpTY3Ah/Ltevr+GZmVmeFvgcQER2SpvVRZR6wKrL/V+JeSSdKehXZsoTfjYgnACR9F2iTtBGYGBH3pvJVwHvJ/g/y+rvzCnjsx4NyaDOzQXfKG+Dca+t+2HpdA5jM4cvg7U5lfZXv7qX8RSQtllSVVO3q6qpTd83M7CX/TeCIWEH6L18rlcqx/c91g5CcZmYjXb3OAPZw+Dqozamsr/LmXsrNzGyI1CsA2oEPpU8DvQl4Kq0ruhZ4Z1pX9CTgncDatG+/pDelT/98CPhfdeqLmZkVUGgKSNJqsgu6jZJ2k32yZyxARNxEtlj1eWRroD5DtmYoEfGEpE+TrekJsLTngjDZaj63kK1LeieDdQHYzMx6NaIWhKlUKuH/DdTM7OhI2hIRldpyfxPYzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSsoBYGZWUg4AM7OScgCYmZVUoQCQ1CbpQUmdkq7oZf9USXdJ2iZpo6Tm3L7rJG1PtwW58rdJ+lEqv1XSS36BejOz0aTfAJDUANwAnAu0ABdKaqmpdj2wKiJagaXA8tT2fOBsYAYwC1giaaKklwG3Agsj4vXAI8CH6zMkMzMrosgZwEygMyIeiojngNuBeTV1WoD1aXtDbn8L0BER3RFxANgGtAGTgOciYmeq913gfcc+DDMzO1pFAmAysCt3f3cqy7sfmJ+2LwAmSJqUytskjZfUCJwDTAF+BYyR1LNG5ftT+YtIWiypKqna1dVVZExmZlZAvS4CLwFmS9oKzAb2AAcjYh2wBrgHWA1sSuUBLAQ+L+mHwK+Bg70dOCJWREQlIipNTU116q6ZmRW58LqHw9+dN6eyQyJiL+kMQNLxwPsiYl/atwxYlvbdBuxM5ZuA30vl7wTOHMhAzMzs6BQ5A9gMTJd0uqRxZO/c2/MVJDWmC7sAVwIrU3lDmgpCUivQCqxL91+Zfh4HfAq4aeDDMTOzovo9A4iIbkmXA2uBBmBlROyQtBSoRkQ7MAdYLimADuCy1HwscLckgP3AoojoTvs+KendZCF0Y0Ssx8zMhoyy6fiRoVKpRLVaHe5umJmNKJK2RESlttzfBDYzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSsoBYGZWUg4AM7OScgCYmZWUA8DMrKQcAGZmJVUoACS1SXpQUqekK3rZP1XSXZK2SdooqTm37zpJ29NtQa787ZJ+JOk+Sd+TdEZ9hmRmZkX0GwCSGoAbgHOBFuBCSS011a4HVkVEK7AUWJ7ang+cDcwAZgFLJE1MbW4EPhgRM4DbgD8f+HDMzKyoImcAM4HOiHgoIp4Dbgfm1dRpAXrW9N2Q298CdEREd0QcALYBbWlfAD1hcAKw99iGYGZmx6JIAEwGduXu705lefcD89P2BcAESZNSeZuk8ZIagXOAKaneJcAaSbuBi4Bre3twSYslVSVVu7q6iozJzMwKqNdF4CXAbElbgdnAHuBgRKwD1gD3AKuBTcDB1OYTwHkR0QzcDHyutwNHxIqIqEREpampqU7dNTOzIgGwhxfetQM0p7JDImJvRMyPiLOAq1LZvvRzWUTMiIi5gICdkpqAN0bED9Ih7gDeMrChmJnZ0SgSAJuB6ZJOlzQOWAi05ytIapTUc6wrgZWpvCFNBSGpFWgF1gFPAidIOjO1mQv8ZKCDMTOz4sb0VyEiuiVdDqwFGoCVEbFD0lKgGhHtwBxguaQAOoDLUvOxwN2SAPYDiyKiG0DSx4D/Kel5skD4g7qOzMzM+qSIGO4+FFapVKJarQ53N8zMRhRJWyKiUlvubwKbmZWUA8DMrKQcAGZmJeUAMDMrKQeAmVlJOQDMzErKAWBmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5IqFACS2iQ9KKlT0hW97J8q6S5J2yRtlNSc23edpO3ptiBXfrek+9Jtr6Rv1WdIZmZWRL8BIKkBuAE4F2gBLpTUUlPtemBVRLQCS4Hlqe35wNnADGAWsETSRICI+L20WPwMYBPwj/UZkpmZFVHkDGAm0BkRD0XEc8DtwLyaOi3A+rS9Ibe/BeiIiO6IOABsA9ryDVMgvA3wGYCZ2RAqEgCTgV25+7tTWd79wPy0fQEwQdKkVN4mabykRuAcYEpN2/cCd0XE/t4eXNJiSVVJ1a6urgLdNTOzIup1EXgJMFvSVmA2sAc4GBHrgDXAPcBqsqmegzVtL0z7ehURKyKiEhGVpqamOnXXzMyKBMAeDn/X3pzKDomIvRExPyLOAq5KZfvSz2Vprn8uIGBnT7t0VjAT+M6ARmFmZketSABsBqZLOl3SOGAh0J6vIKlRUs+xrgRWpvKGNBWEpFagFViXa/p+4NsR8ezAhmFmZkdrTH8VIqJb0uXAWqABWBkROyQtBaoR0Q7MAZZLCqADuCw1HwvcLQlgP7AoIrpzh18IXFuvwZiZWXGKiOHuQ2GVSiWq1epwd8PMbESRtCUiKrXl/iawmVlJOQDMzErKAWBmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyupQgEgqU3Sg5I6JV3Ry/6pku6StE3SRknNuX3XSdqebgty5ZK0TNJOST+R9F/qMyQzMyui3yUhJTUANwBzgd3AZkntEfFArtr1wKqIuFXS24DlwEWSzgfOBmYAxwEbJd0ZEfuBi8kWm39tRDwv6ZX1HJiZmfWtyBnATKAzIh6KiOeA24F5NXVagPVpe0NufwvQERHdEXEA2Aa0pX2XAksj4nmAiPjlsQ/DzMyOVpEAmAzsyt3fncry7gfmp+0LgAmSJqXyNknjJTUC55C96wd4DbBAUlXSnZKm9/bgkhanOtWurq5iozIzs37V6yLwEmC2pK3AbGAPcDAi1gFrgHuA1cAm4GBqcxzwbFqo+MvAyt4OHBErIqISEZWmpqY6ddfMzIoEwB5eeNcO0JzKDomIvRExPyLOAq5KZfvSz2URMSMi5gICdqZmu4F/TNv/BLQe8yjMzOyoFQmAzcB0SadLGgcsBNrzFSQ1Suo51pWkd/OSGtJUEJJayV7k16V63yKbEoLsrGEnZmY2ZPr9FFBEdEu6HFgLNAArI2KHpKVANSLagTnAckkBdACXpeZjgbslAewHFkVEd9p3LfA1SZ8AngYuqd+wzMysP4qI4e5DYZVKJarV6nB3w8xsRJG0JV1vPYy/CWxmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSqpQAEhqk/SgpE5JV/Syf6qkuyRtk7RRUnNu33WStqfbglz5LZJ+Lum+dJtRnyGZmVkR/QaApAbgBuBcoAW4UFJLTbXrgVUR0QosBZantucDZwMzgFnAEkkTc+0+mRaMnxER9w14NGZmVliRM4CZQGdEPBQRzwG3A/Nq6rQA69P2htz+FqAjIroj4gCwDWgbeLfNzGygigTAZGBX7v7uVJZ3PzA/bV8ATJA0KZW3SRovqRE4B5iSa7csTRt9XtJxvT24pMWSqpKqXV1dBbprZmZF1Osi8BJgtqStwGxgD3AwItYBa4B7gNXAJuBganMl8Frgd4CTgU/1duCIWBERlYioNDU11am7ZmZWJAD2cPi79uZUdkhE7I2I+RFxFnBVKtuXfi5Lc/xzAQE7U/mjkfkNcDPZVJOZmQ2RIgGwGZgu6XRJ44CFQHu+gqRGST3HuhJYmcob0lQQklqBVmBduv+q9FPAe4HtAx+OmZkVNaa/ChHRLelyYC3QAKyMiB2SlgLViGgH5gDLJQXQAVyWmo8F7s5e49kPLIqI7rTva5KayM4K7gP+sH7DMjOz/igihrsPhVUqlahWq8PdDTOzEUXSloio1Jb7m8BmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyspB4CZWUk5AMzMSsoBYGZWUg4AM7OScgCYmZWUA8DMrKQKBYCkNkkPSuqUdEUv+6dKukvSNkkbJTXn9l0naXu6Leil7RckPT2wYZiZ2dHqNwAkNQA3AOcCLcCFklpqql0PrIqIVmApsDy1PR84G5gBzAKWSJqYO3YFOKkO4zAzs6NU5AxgJtAZEQ9FxHPA7cC8mjotwPq0vSG3vwXoiIjuiDgAbAPa4FCw/A3wZwMbgpmZHYsiATAZ2JW7vzuV5d0PzE/bFwATJE1K5W2SxktqBM4BpqR6lwPtEfFoXw8uabGkqqRqV1dXge6amVkR9boIvASYLWkrMBvYAxyMiHXAGuAeYDWwCTgo6VTgPwJ/19+BI2JFRFQiotLU1FSn7pqZWZEA2MML79oBmlPZIRGxNyLmR8RZwFWpbF/6uSwiZkTEXEDATuAs4AygU9LDwHhJnQMdjJmZFTemQJ3NwHRJp5O98C8EPpCvkKZ3noiI54ErgZWpvAE4MSIel9QKtALrIqIbOCXX/umIOKMeAzIzs2L6DYCI6JZ0ObAWaABWRsQOSUuBakS0A3OA5ZIC6AAuS83HAndLAtgPLEov/mZmNswUEcPdh8IqlUpUq9Xh7oaZ2YgiaUtEVGrL/U1gM7OScgCYmZWUA8DMrKQcAGZmJeUAMDMrKQeAmVlJOQDMzErKAWBmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKqlAASGqT9KCkTklX9LJ/qqS7JG2TtFFSc27fdZK2p9uCXPlXJN2f2nxT0vH1GZKZmRXRbwCkZR1vAM4FWoALJbXUVLseWBURrcBSYHlqez5wNjADmAUskTQxtflERLwxtfkFcHkdxmNmZgUVOQOYCXRGxEMR8RxwOzCvpk4LsD5tb8jtbwE6IqI7Ig4A24A2gIjYD6BsvchXACNnaTIzs1GgSABMBnbl7u9OZXn3A/PT9gXABEmTUnmbpPFp4fhzgCk9jSTdDDwGvBb4u2MagZmZHZN6XQReAsyWtBWYDewBDkbEOmANcA+wGtgEHOxpFBEfAU4FfgIsqD0ogKTFkqqSql1dXXXqrpmZFQmAPeTetQPNqeyQiNgbEfMj4izgqlS2L/1cFhEzImIuIGBnTduDZNNK7+vtwSNiRURUIqLS1NRUcFhmZtafIgGwGZgu6XRJ44CFQHu+gqRGST3HuhJYmcob0lQQklqBVmCdMmekcgHvAX5ajwGZmVkxY/qrEBHdki4H1gINwMqI2CFpKVCNiHZgDrBcUgAdwGWp+Vjg7uw1nv3AonS8lwG3pk8EiexawaX1HZqZmfVFESPnwzeVSiWq1epwd8PMbESRtCUiKrXl/iawmVlJOQDMzErKAWBmVlIOADOzknIAmJmVlAPAzKykHABmZiXlADAzKykHgJlZSTkAzMxKygFgZlZSDgAzs5JyAJiZlZQDwMyspBwAZmYl5QAwMyupQgEgqU3Sg5I6JV3Ry/6pku6StE3SRknNuX3XSdqebgty5V9Lx9wuaaWksfUZkpmZFdHvkpCSGoAbgLnAbmCzpPaIeCBX7XpgVUTcKultwHLgIknnA2cDM4DjgI2S7oyI/cDXgEWp/W3AJcCNdRrXYf7qf+/ggb37B+PQZmaDruXUiVz9+6+r+3GLnAHMBDoj4qGIeA64HZhX2z9gfdrekNvfAnRERHdEHAC2AW0AEbEmEuCHQDNmZjZk+j0DACYDu3L3dwOzaurcD8wH/gdwATBB0qRUfrWkzwLjgXOA/JkDaernIuCPe3twSYuBxQCnnXZage6+2GAkp5nZSFevi8BLgNmStgKzgT3AwYhYB6wB7gFWA5uAgzVtv0h2lnB3bweOiBURUYmISlNTU526a2ZmRQJgDzAld785lR0SEXsjYn5EnAVclcr2pZ/LImJGRMwFBOzsaSfpaqAJ+JMBjcLMzI5akQDYDEyXdLqkccBCoD1fQVKjpJ5jXQmsTOUNaSoISa1AK7Au3b8EeBdwYUQ8X4/BmJlZcf0GQER0A5cDa4GfAF+PiB2Slkp6T6o2B3hQ0k7g3wPLUvlY4G5JDwArgEXpeAA3pbqbJN0n6S/rNSgzM+ufsg/hjAyVSiWq1epwd8PMbESRtCUiKrXl/iawmVlJOQDMzErKAWBmVlIj6hqApC7gkWNs3gj8qo7dGQk85nLwmEe/gY53akS86ItUIyoABkJStbeLIKOZx1wOHvPoN1jj9RSQmVlJOQDMzEqqTAGwYrg7MAw85nLwmEe/QRlvaa4BmJnZ4cp0BmBmZjkOADOzkhp1AVBg/eLjJN2R9v9A0rSh72V9FRjzn0h6IK3ZfJekqcPRz3rqb8y5eu+TFJJG9EcGi4xX0n9Kv+cdkm4b6j7WW4G/69MkbZC0Nf1tnzcc/ayntD76LyVtP8J+SfpCek62STp7QA8YEaPmBjQAPwNeDYwjW5GspabOx4Gb0vZC4I7h7vcQjPkcYHzavrQMY071JgAdwL1AZbj7Pci/4+nAVuCkdP+Vw93vIRjzCuDStN0CPDzc/a7DuN9Kto769iPsPw+4k2xtlTcBPxjI4422M4Ai6xfPA25N298E3i5JQ9jHeut3zBGxISKeSXfvZeSvv1zk9wzwaeA64Nmh7NwgKDLejwE3RMSTABHxyyHuY70VGXMAE9P2CcDeIezfoIiIDuCJPqrMA1ZF5l7gREmvOtbHG20B0Nv6xZOPVCeytQmeAiYNSe8GR5Ex532U7B3ESNbvmNOp8ZSI+M5QdmyQFPkdnwmcKen7ku6V1DZkvRscRcZ8DbBI0m6ypWf/aGi6NqyO9t97n4osCm+jhKRFQIVs3eZRK61O9zng4mHuylAaQzYNNIfsDK9D0hsiLc06Sl0I3BIRn5X0ZuAfJL0+vMJgYaPtDKDf9YvzdSSNITt1fHxIejc4iowZSe8gW6/5PRHxmyHq22Dpb8wTgNcDGyU9TDZX2j6CLwQX+R3vBtoj4t8i4udka29PH6L+DYYiY/4o8HWAiNgEvJzsP00bzQr9ey9qtAVAv+sXp/sfTtvvB9ZHuroyQhVZs/ks4EtkL/4jfW4Y+hlzRDwVEY0RMS0ippFd93hPRIzU5eSK/F1/i+zdP5IayaaEHhrKTtZZkTH/Ang7gKTfIguAriHt5dBrBz6UPg30JuCpiHj0WA82qqaAIqJbUs/6xQ3AykjrFwPViGgHvkJ2qthJdrFl4fD1eOAKjvlvgOOBb6Tr3b+IiPcc8aAvcQXHPGoUHO9a4J1p/e2DwCcjYsSe2RYc858CX5b0CbILwheP8DdzSFpNFuSN6drG1WRrqxMRN5Fd6zgP6ASeAT4yoMcb4c+XmZkdo9E2BWRmZgU5AMzMSsoBYGZWUg4AM7OScgCYmZWUA8DMrKQcAGZmJfX/AaIWpuxpW8ijAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD2wqV2sNCBm",
        "outputId": "aaea6819-2b6e-4e98-edee-964d7697c3c9"
      },
      "source": [
        "model.evaluate(X, y, verbose=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04695957154035568, 0.9928825497627258]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q3gEz80lXltJ",
        "outputId": "25fbe383-423f-4163-ba8c-251a2347f32b"
      },
      "source": [
        "seed_text=lines[0]\n",
        "seed_text"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'on weekdays except friday this is from monday to thursday i'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgqu8cYpO--z"
      },
      "source": [
        "\n",
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "3uXN43vqNUHs",
        "outputId": "0668b0ee-cc84-4687-dc65-ac24e5f43fd0"
      },
      "source": [
        "\n",
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 15+5 )\n",
        "\n",
        " \n",
        " "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'get up early at half past seven i have a white coffee and biscuits for breakfast and i go to'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "3jd-CagnQkMA",
        "outputId": "8220134f-28bc-4321-a1b6-5ff2e20656e5"
      },
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "def prediction_text(seed_text,n_words):    \n",
        " text_seq_length = 3\n",
        " # seed_text =             \"this is the\" ...\n",
        " output = generate_text_seq(model, tokenizer, text_seq_length, seed_text, int(n_words)) \n",
        " return output\n",
        "\n",
        "\n",
        "iface = gr.Interface(fn=prediction_text, inputs= [\"text\", \"text\"], outputs=\"text\")\n",
        "iface.launch()\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://41229.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://41229.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fbdefaf0fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://41229.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}